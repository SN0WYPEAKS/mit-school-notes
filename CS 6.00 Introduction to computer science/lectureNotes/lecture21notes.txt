lecture notes on the board:
    Pi estimation from last lectures algorithm:
        3.14161124
    When you recieve a result ask:
        how many samples would it take for me to believe the result
        how accurate do I think it is with the current amount of examples
    It is almost impossible to know whether we have a biased sample unless we look at the entire population
    statistical validity does not equal correctness
    check result against physical reality
    what happens when:
        you have data from measurements
        models that at least claim to explain the data
        and consequences that follow from the models
    spring constant(how stiff the spring is):
        hooke's law:
            force = -(some constant)*(the distance you have compressed the spring)
            f = -kx
            how do we fit a line to the test data
    whenever we try to fit something:
    objective function:
        the real-valued function whose value is to be either minimized or maximized subject to the constraints
        we need an objective function:
            that captures the goodness of the fit
            least squares fit:
                a mathematical technique that allows the analyst to determine
                the best way of fitting a curve on top of a chart of data points
            to find the line that minimizes the sum of the observation sub i minus what the line(model) predicts the point should have been and square it
            {(observationSUBi-predictionSUBi)}squared
            by squaring the result it's like getting the absolute value for it
    polyfit(a built in pylab function):
        given a set of points, finds the polynomial that gives the best least squares approximation to those points
        ax + b (distances, forces, i)
    linear regression:
        y = ax**2 + bx + c
    r**2 - coefficient of determination
    r**2 = 1 - ee over de
    r**2 = 0.9
    lurking variables:
        a variable that is not included in a statistical analysis
        but can still affect the outcome of that analysis
    closer does not equal better:
        overfit the data:
            an undesirable machine learning behavior that occurs when the machine learning model
            gives accurate predictions for training data but not for new data
    
definitions for the title subjects:
    validating simulation results:
        the process of checking whether your simulation model is a good representation of the real system
    curve fitting:
        the process of constructing a cureve, or mathematical function,
        that has the best fit to a series of data points,
        possibly subject to constraints
    linear regression:
        used to predict the value of a variable based on the value of another variable
